{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a37277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "# useful stuff\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05703685",
   "metadata": {},
   "outputs": [],
   "source": [
    "__authors__ = ['author1','author2','author3']\n",
    "__emails__  = ['fatherchristmoas@northpole.dk','toothfairy@blackforest.no','easterbunny@greenfield.de']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a2dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2sentences(path):\n",
    "    # feel free to make a better tokenization/pre-processing\n",
    "    sentences = []\n",
    "    with open(path) as f:\n",
    "        for l in f:\n",
    "            sentences.append( l.lower().split() )\n",
    "    return sentences\n",
    "\n",
    "def loadPairs(path):\n",
    "    data = pd.read_csv(path, delimiter='\\t')\n",
    "    pairs = zip(data['word1'],data['word2'],data['similarity'])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram:\n",
    "    def __init__(self, sentences, nEmbed=100, negativeRate=5, winSize = 5, minCount = 5):\n",
    "        self.w2id = {} # word to ID mapping\n",
    "        self.trainset = {} # set of sentences\n",
    "        self.vocab = {} # list of valid words\n",
    "        raise NotImplementedError('implement it!')\n",
    "\n",
    "    def sample(self, omit):\n",
    "        \"\"\"samples negative words, ommitting those in set omit\"\"\"\n",
    "        raise NotImplementedError('this is easy, might want to do some preprocessing to speed up')\n",
    "\n",
    "    def train(self):\n",
    "        for counter, sentence in enumerate(self.trainset):\n",
    "            sentence = filter(lambda word: word in self.vocab, sentence)\n",
    "\n",
    "            for wpos, word in enumerate(sentence):\n",
    "                wIdx = self.w2id[word]\n",
    "                winsize = np.random.randint(self.winSize) + 1\n",
    "                start = max(0, wpos - winsize)\n",
    "                end = min(wpos + winsize + 1, len(sentence))\n",
    "\n",
    "                for context_word in sentence[start:end]:\n",
    "                    ctxtId = self.w2id[context_word]\n",
    "                    if ctxtId == wIdx: continue\n",
    "                    negativeIds = self.sample({wIdx, ctxtId})\n",
    "                    self.trainWord(wIdx, ctxtId, negativeIds)\n",
    "                    self.trainWords += 1\n",
    "\n",
    "            if counter % 1000 == 0:\n",
    "                print ' > training %d of %d' % (counter, len(self.trainset))\n",
    "                self.loss.append(self.accLoss / self.trainWords)\n",
    "                self.trainWords = 0\n",
    "                self.accLoss = 0.\n",
    "\n",
    "    def trainWord(self, wordId, contextId, negativeIds):\n",
    "        raise NotImplementedError('here is all the fun!')\n",
    "\n",
    "    def save(self,path):\n",
    "        raise NotImplementedError('implement it!')\n",
    "\n",
    "    def similarity(self,word1,word2):\n",
    "        \"\"\"\n",
    "            computes similiarity between the two words. unknown words are mapped to one common vector\n",
    "        :param word1:\n",
    "        :param word2:\n",
    "        :return: a float \\in [0,1] indicating the similarity (the higher the more similar)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('implement it!')\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path):\n",
    "        raise NotImplementedError('implement it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d158447",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--text', help='path containing training data', required=True)\n",
    "    parser.add_argument('--model', help='path to store/read model (when training/testing)', required=True)\n",
    "    parser.add_argument('--test', help='enters test mode', action='store_true')\n",
    "\n",
    "    opts = parser.parse_args()\n",
    "\n",
    "    if not opts.test:\n",
    "        sentences = text2sentences(opts.text)\n",
    "        sg = SkipGram(sentences)\n",
    "        sg.train(...)\n",
    "        sg.save(opts.model)\n",
    "\n",
    "    else:\n",
    "        pairs = loadPairs(opts.text)\n",
    "\n",
    "        sg = SkipGram.load(opts.model)\n",
    "        for a,b,_ in pairs:\n",
    "            # make sure this does not raise any exception, even if a or b are not in sg.vocab\n",
    "            print(sg.similarity(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd47b1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0c48db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--test'], dest='test', nargs=0, const=True, default=False, type=None, choices=None, help='enters test mode', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--text', help='path containing training data', required=True)\n",
    "    parser.add_argument('--model', help='path to store/read model (when training/testing)', required=True)\n",
    "    parser.add_argument('--test', help='enters test mode', action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b2a54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --text TEXT --model MODEL [--test]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --text, --model\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Axe-Yue-CHEN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "    opts = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f61693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd11ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770269db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b08107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01d788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
